# Project2-ETL
For the ETL mini project, I undertook the task independently, leveraging my skills in Python, Pandas, and data manipulation techniques to build an ETL (Extract, Transform, Load) pipeline. The project involved collaborating with a partner to handle various aspects of the pipeline. Initially, I extracted and transformed data from the provided crowdfunding.xlsx Excel file, creating DataFrames for categories, subcategories, campaigns, and contacts. I ensured proper data cleaning, conversion, and formatting to meet the project requirements. Subsequently, I created four CSV files from these DataFrames, each representing a different aspect of the crowdfunding data.

After creating the CSV files, I participated in developing an Entity-Relationship Diagram (ERD) by inspecting the data and using QuickDBD to visualize the relationships between tables. With the ERD as a guide, I created a table schema for each CSV file, specifying data types, primary keys, foreign keys, and other constraints. The resulting database schema was saved as a Postgres SQL file named crowdfunding_db_schema.sql.

Moving forward, I contributed to the creation of a new Postgres database named crowdfunding_db, ensuring the correct order of table creation to handle foreign keys. I verified the successful creation of each table by executing SELECT statements. The final steps involved importing each CSV file into its corresponding SQL table and confirming the accuracy of the data with additional SELECT statements.

Throughout the project, effective collaboration and communication were emphasized, and I regularly checked in with my partner to provide support and ensure a cohesive workflow. The project aimed to build practical skills in ETL processes and database management, fostering an understanding of how to transform raw data into a structured and usable format for analysis.
