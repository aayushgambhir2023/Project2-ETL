# Project2-ETL
For the ETL mini project, I undertook the task independently, leveraging my skills in Python, Pandas, and data manipulation techniques to build an ETL (Extract, Transform, Load) pipeline. Initially, I extracted and transformed data from the provided crowdfunding.xlsx Excel file, creating DataFrames for categories, subcategories, campaigns, and contacts. I ensured proper data cleaning, conversion, and formatting to meet the project requirements. Subsequently, I created four CSV files from these DataFrames, each representing a different aspect of the crowdfunding data.

After creating the CSV files, I participated in developing an Entity-Relationship Diagram (ERD) by inspecting the data and using QuickDBD to visualize the relationships between tables. With the ERD as a guide, I created a table schema for each CSV file, specifying data types, primary keys, foreign keys, and other constraints. The resulting database schema was saved as a Postgres SQL file named crowdfunding_db_schema.sql.

Moving forward, I handled the creation of a new Postgres database named crowdfunding_db, ensuring the correct order of table creation to handle foreign keys. I verified the successful creation of each table by executing SELECT statements. The final steps involved importing each CSV file into its corresponding SQL table and confirming the accuracy of the data with additional SELECT statements.

Throughout the project, I emphasized effective collaboration and communication, ensuring a cohesive workflow and maintaining a clear understanding of the tasks at hand.  The primary goal of the project remained consistent: to build practical skills in ETL processes and database management. By engaging in this project solo, I aimed to deepen my understanding of how to extract, transform, and load data effectively, ultimately transforming raw data into a structured and usable format suitable for analysis.
